<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Experiment 16 - .NET Experiments</title>
<meta name="description" content="This post explores unique concepts in few-shot learning.">


  <meta name="author" content="Daniel Felps">
  
  <meta property="article:author" content="Daniel Felps">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content=".NET Experiments">
<meta property="og:title" content="Experiment 16">
<meta property="og:url" content="https://dlfelps.github.io/2024/06/03/few-shot.html">


  <meta property="og:description" content="This post explores unique concepts in few-shot learning.">







  <meta property="article:published_time" content="2024-06-03T00:00:00+00:00">






<link rel="canonical" href="https://dlfelps.github.io/2024/06/03/few-shot.html">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title=".NET Experiments Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script type="text/javascript">
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          .NET Experiments
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="https://mmistakes.github.io/minimal-mistakes/docs/quick-start-guide/"
                
                
              >Quick-Start Guide</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Experiment 16">
    <meta itemprop="description" content="This post explores unique concepts in few-shot learning.">
    <meta itemprop="datePublished" content="2024-06-03T00:00:00+00:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://dlfelps.github.io/2024/06/03/few-shot.html" itemprop="url">Experiment 16
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2024-06-03T00:00:00+00:00">June 3, 2024</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          14 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#introduction">Introduction</a></li><li><a href="#experiment">Experiment</a><ul><li><a href="#few-shot-framework-prototype-model">Few-shot framework: Prototype model</a></li><li><a href="#approach-1-pretrained-model">Approach #1: Pretrained model</a></li><li><a href="#approach-2-classical-model">Approach #2: Classical model</a></li><li><a href="#approach-3-episodic-model">Approach #3: Episodic model</a></li><li><a href="#bonus-approach-pretrained-model-dinov2-backbone">BONUS Approach: Pretrained model (DINOv2 backbone)</a></li></ul></li><li><a href="#results">Results</a></li><li><a href="#conclusion">Conclusion</a><ul><li><a href="#footnotes">Footnotes</a></li></ul></li></ul>
            </nav>
          </aside>
        
        <p>This post explores unique concepts in few-shot learning.</p>

<h2 id="introduction">Introduction</h2>

<p>Few-shot learning describes the situation where a classifier must generalize to new classes using only a few examples of each new class. It represents scenarios where data collection (or annotation) is costly for the classes you care about, but you may have access to related data. There are some unique terms associated with few-shot learning, which we will introduce next.</p>

<p>In standard supervised learning, the training and testing sets contain the SAME classes. The classifier is tested for its ability to discriminate between KNOWN classes.</p>

<p><img src="/assets/images/supervised_learning.PNG" alt="supervised learning" title="supervised learning" /></p>

<p><a href="https://ieeexplore.ieee.org/document/10287966">image reference</a></p>

<p>In few-shot learning, the training and testing sets contain DIFFERENT classes. A few-shot classifier is tested for its ability to discriminate UNKNOWN classes given only a few examples. These samples are further divided into the support set and query set. The support set contains labeled examples (for tuning the few-shot classifier) and the query set contains unlabeled samples for evaluation. The number of classes in the support set is denoted by N and the number of examples per class is denoted by K. A 5-way 1-shot method describes a method that has (N=5) classes with (K=1) examples per class.</p>

<p><img src="/assets/images/few_shot_learning.PNG" alt="few_shot_learning" title="few_shot_learning" /></p>

<p><a href="https://ieeexplore.ieee.org/document/10287966">image reference</a></p>

<h2 id="experiment">Experiment</h2>

<p>This experiment will test a model in a 5-way 5-shot task (i.e. 5 new classes, 5 examples each). We will use a standard benchmark in few-shot learning -  <a href="https://www.vision.caltech.edu/datasets/cub_200_2011/">CUB-200-2011</a> dataset. It is a fine-grained image classification task with over 200 different species of birds. The large number of classes make it suitable for few-shot learning as several can be withheld for testing while maintaining a difficult baseline. We next explain our basic approach to few-shot learning (prototype models) and then compare the performance of three ways to train the model.</p>

<h3 id="few-shot-framework-prototype-model">Few-shot framework: Prototype model</h3>

<p>We adopt a single framework for all variations of our experiment - <a href="https://arxiv.org/abs/1703.05175">Prototypical networks</a>. The concept is based on the idea that there is a single prototype representation for each class. A prototype for each class is calculated from the mean of its support set in the embedding space of a neural network. Our three approaches explore three different ways to train this neural network. Classification in a prototypical model is simply a nearest neighbors using only the prototypes<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. The code uses models and task loaders from <a href="https://github.com/sicara/easy-few-shot-learning">Easy Few-shot learning</a>.</p>

<p><img src="/assets/images/prototypical_network.jpeg" alt="prototypical network" title="prototypical network" /></p>

<p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221001818">image reference</a></p>

<h3 id="approach-1-pretrained-model">Approach #1: Pretrained model</h3>

<p>The first approach adapts a pretrained model using transfer learning. The transfer learning process starts with a model that is trained on a large and general dataset (e.g. Imagenet). The purpose of this model is to rely on the learned feature maps - which should be robust - and adapt the later layers to classify your new classes (see image below).</p>

<p><img src="/assets/images/transfer_learning.png" alt="transfer model" title="transfer model" /></p>

<p><a href="https://www.nature.com/articles/s41598-024-54923-y">image reference</a></p>

<p>This experiment uses a ResNet-18 model with pretrained weights from an Imagenet dataset. For each task in the evaluation phase, the support set is used to calculate the prototypes and the the query sets are classified from the prototypes.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model = resnet18(weights=ResNet18_Weights.DEFAULT)
model.fc = nn.Flatten()
few_shot_classifier = PrototypicalNetworks(model).to(DEVICE)
</code></pre></div></div>

<h3 id="approach-2-classical-model">Approach #2: Classical model</h3>

<p>This approach uses a subset of the training data to generate a pretrained model. NOTE: the test data contains classes that were not included in the training data. This approach is not always viable since it requires prior knowledge of the few-shot task data distribution. However, it can be powerful if you work in a specific domain and have labeled data from that domain readily available. To simulate it here, we split the 200 species in CUB into 140 for training and 60 for testing. During test time, a 5-way 5-shot task is created by randomly sampling 5 classes from the 60 test classes. This process is repeated 500 times to get a statistically significant measure of generalization performance.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model = resnet18()
model.fc = nn.Linear(512, 140)
model.load_state_dict(torch.load('/content/easy-few-shot-learning/classical_model_18_acc_744.pt')) # pretrained just for you!
few_shot_classifier = PrototypicalNetworks(model).to(DEVICE)
</code></pre></div></div>

<h3 id="approach-3-episodic-model">Approach #3: Episodic model</h3>

<p>Episodic training (also called meta-learning) mirrors the few-shot tasks that will be used to test the final model during the training phase. Each “episode” is designed to mimic the few-shot task by subsampling classes as well as data points. The use of episodes makes the training problem more faithful to the test environment and thereby improves generalization. This strategy typically assumes prior knowledge of N and K that will be used at test time. <a href="https://arxiv.org/pdf/2204.11181">ref1</a> <a href="https://arxiv.org/pdf/1703.05175">ref2</a></p>

<p>Episodic training can be performed following a classic training regime if additional data is available or using pretrained-weights if it is not. In this case we reserve the same 140 classes as in Approach #2 for training. But instead of performing classic training, which reduces cross entropy across all classes, we adjust weights based on many training episodes (5-way 5-shot). This process is slower as there is additional overhead required for each episode.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>model = resnet18()
model.fc = nn.Flatten()
model.load_state_dict(torch.load('/content/easy-few-shot-learning/episodic_model_18_acc_779.pt')) # pretrained just for you!
few_shot_classifier = PrototypicalNetworks(model).to(DEVICE)
</code></pre></div></div>

<h3 id="bonus-approach-pretrained-model-dinov2-backbone">BONUS Approach: Pretrained model (DINOv2 backbone)</h3>

<p>The three primary variations above can be compared directly because they are all variations of Resnet-18 and use Prototypical models for evaluation. In this bonus approach, we replace the Resnet-18 backbone of the pretrained model (approach #1) with DINOv2. The rest of the setup is the same.</p>

<h2 id="results">Results</h2>

<p>For this purposes of this discussion we will focus on Approaches #1-#3. The accuracy improves with each successive approach, but the assumptions also increase. Namely, in moving from transfer learning to classic learning we assume knowledge of the domain of the test classes and also assume access to labeled examples from that domain. In moving from classic learning to episodic learning we further assume knowledge of the task itself (5-way 5-shot) and the distribution of the data within it (i.e. uniformly sampled). This does not always reflect the real word - a <a href="https://arxiv.org/abs/2204.11181">study</a> showed that if these assumptions are incorrect they can impact performance significantly.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Backbone</th>
      <th style="text-align: center">Training approach</th>
      <th style="text-align: center">Accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Resnet-18</td>
      <td style="text-align: center">transfer learning</td>
      <td style="text-align: center">0.684</td>
    </tr>
    <tr>
      <td style="text-align: center">Resnet-18</td>
      <td style="text-align: center">classic</td>
      <td style="text-align: center">0.773</td>
    </tr>
    <tr>
      <td style="text-align: center">Resnet-18</td>
      <td style="text-align: center">episodic</td>
      <td style="text-align: center">0.779</td>
    </tr>
    <tr>
      <td style="text-align: center">DINOv2</td>
      <td style="text-align: center">transfer learning</td>
      <td style="text-align: center">0.964</td>
    </tr>
  </tbody>
</table>

<h2 id="conclusion">Conclusion</h2>

<p>We compared three approaches to few-shot learning and discussed the conditions and assumptions necessary to use them. The code for this experiment can be found at my <a href="https://github.com/dlfelps/ml_portfolio">ML portfolio website</a>.</p>

<h3 id="footnotes">Footnotes</h3>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>There is some similarity between Prototypical models and Image retrieval tasks. Image retrieval can be viewed as a prototypical model where each image is its own prototype. And instead of returing a single class, the top-N closest prototypes are returned. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/computer-vision" class="page__taxonomy-item p-category" rel="tag">computer-vision</a><span class="sep">, </span>
    
      <a href="/tags/few-shot" class="page__taxonomy-item p-category" rel="tag">few-shot</a><span class="sep">, </span>
    
      <a href="/tags/meta-learning" class="page__taxonomy-item p-category" rel="tag">meta-learning</a><span class="sep">, </span>
    
      <a href="/tags/ml-portfolio" class="page__taxonomy-item p-category" rel="tag">ml-portfolio</a>
    
    </span>
  </p>




        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-06-03T00:00:00+00:00">June 3, 2024</time></p>

      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Experiment+16%20https%3A%2F%2Fdlfelps.github.io%2F2024%2F06%2F03%2Ffew-shot.html" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdlfelps.github.io%2F2024%2F06%2F03%2Ffew-shot.html" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://dlfelps.github.io/2024/06/03/few-shot.html" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/2024/06/02/VIT-amster.html" class="pagination--pager" title="Experiment 15
">Previous</a>
    
    
      <a href="/2024/06/04/explainable.html" class="pagination--pager" title="Experiment 17
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

      
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 <a href="https://dlfelps.github.io">.NET Experiments</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>









  </body>
</html>
