<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.26.2 by Michael Rose
  Copyright 2013-2024 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Experiment 19 - .NET Experiments</title>
<meta name="description" content="This post describes the stable diffusion architecture for generative AI.">


  <meta name="author" content="Daniel Felps">
  
  <meta property="article:author" content="Daniel Felps">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content=".NET Experiments">
<meta property="og:title" content="Experiment 19">
<meta property="og:url" content="https://dlfelps.github.io/2024/08/01/generative.html">


  <meta property="og:description" content="This post describes the stable diffusion architecture for generative AI.">







  <meta property="article:published_time" content="2024-08-01T00:00:00+00:00">






<link rel="canonical" href="https://dlfelps.github.io/2024/08/01/generative.html">












<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title=".NET Experiments Feed">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script type="text/javascript">
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          .NET Experiments
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="https://mmistakes.github.io/minimal-mistakes/docs/quick-start-guide/"
                
                
              >Quick-Start Guide</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Experiment 19">
    <meta itemprop="description" content="This post describes the stable diffusion architecture for generative AI.">
    <meta itemprop="datePublished" content="2024-08-01T00:00:00+00:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">
            <a href="https://dlfelps.github.io/2024/08/01/generative.html" itemprop="url">Experiment 19
</a>
          </h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2024-08-01T00:00:00+00:00">August 1, 2024</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          15 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#introduction">Introduction</a></li><li><a href="#unconditional-image-generation-denoising-diffusion-probabilistic-models">Unconditional Image Generation (Denoising Diffusion Probabilistic Models)</a></li><li><a href="#generating-higher-resolution-images">Generating Higher Resolution Images</a><ul><li><a href="#upscaling">Upscaling</a></li><li><a href="#latent-model">Latent model</a></li></ul></li><li><a href="#conditional-image-generation-stable-diffusion">Conditional Image Generation (Stable Diffusion)</a></li><li><a href="#conclusion">Conclusion</a></li></ul>
            </nav>
          </aside>
        
        <p>This post describes the stable diffusion architecture for generative AI.</p>

<h1 id="introduction">Introduction</h1>

<p>I am going to introduce this post with a real conversation I had with Microsoft’s <a href="https://copilot.microsoft.com/">Copilot</a>:</p>

<blockquote>
  <p style="text-align: right;">Me:</p>
  <p style="text-align: right;">Can you explain Generative AI to me like I am 5 years old?</p>

  <p>Copilot:</p>

  <p>Certainly! Imagine you have a magical drawing book. When you open it, it creates new pictures all by itself! That’s what generative AI does—it makes up things like drawings, stories, or even songs without anyone telling it exactly what to create. It’s like having a creative friend who invents cool stuff just by thinking about it! 🎨✨</p>

  <p style="text-align: right;">Me:</p>
  <p style="text-align: right;">Are you an example of a Generative AI?</p>

  <p>Copilot:</p>

  <p>Indeed! I’m like a friendly digital artist. When you ask me for something, I use my magical algorithms to create new sentences, poems, or even drawings. Just like a painter mixes colors to create beautiful pictures, I mix words and ideas to make interesting content! 🎨✨</p>

  <p style="text-align: right;">Me:</p>
  <p style="text-align: right;">Can you generate an image of an Eastern Bluebird drinking a milkshake?</p>

  <p>Copilot:</p>

  <p><img src="/assets/images/bluebird_milkshake_dalle.PNG" alt="bluebird milkshake" /></p>
</blockquote>

<p>END OF CONVERSATION</p>

<p>I was impressed by the generated images. Behind the scenes, Copilot uses an OpenAI product called <a href="https://openai.com/dall-e-3/">DALLE-3</a> to generate images. Unfortunately DALLE-3 is not publicly available. So, for the remainder of this post, we will instead examine a closely related model called Stable Diffusion. How do they compare? Here is the output of Stable Diffusion for the same prompt above:</p>

<p><img src="/assets/images/bluebird_milkshake_stable.webp" alt="stable diffusion" width="400" /></p>

<p>Generally Stable Diffusion tends to produce images that are more photorealistic whereas DALLE-3 creates images that feel like computer-generated art.</p>

<h1 id="unconditional-image-generation-denoising-diffusion-probabilistic-models">Unconditional Image Generation (Denoising Diffusion Probabilistic Models)</h1>

<p>I will explain Stable Diffusion through a series of increasingly complex models. The first - and most foundational model -  is the Denoising Diffusion Probabilistic Model (DDPM), which serves as the core technology behind Stable Diffusion and DALLE-3.</p>

<p>DDPMs are a class of generative models that work by iteratively denoising a diffusion process, which involves adding noise to an image and then trying to remove it. The underlying theory of DDPMs is based on the idea that transforming a simple distribution, such as a Gaussian, through a series of diffusion steps can result in a complex and expressive image data distribution. This allows the model to generate new images by reversing the diffusion process, starting from the full Gaussian distribution and ending up with the image distribution.</p>

<p><img src="https://huggingface.co/blog/assets/78_annotated-diffusion/diffusion_figure.png" alt="forward diffusion" /></p>

<p>To further demonstrate the contribution of each step I will show what kind of generative images are possible using the CUB-2011 dataset. Our final goal will be to produce fully synthetic birds. In this first step we will only be able to generate small bird-like shapes using the DDPM architecture alone.</p>

<p><img src="/assets/images/generative_figure1.png" alt="ddpm" width="400" /></p>

<p>Figure adapted from https://huggingface.co/blog/stable_diffusion</p>

<p>The output of training the model is shown below. Here I take a snapshot of the sample images every 10 epochs to show the learning progression of the model.</p>

<p><img src="/assets/images/ddpm-64.gif" alt="ddpm animation" /></p>

<p>You can see birds if you squint, but the low resolution (64x64) makes these images less useful. DDPMs top out around (256x256) and become increasingly slow to train on a single GPU. We next explore two options for increasing the resolution.</p>

<h1 id="generating-higher-resolution-images">Generating Higher Resolution Images</h1>

<p>The following two sections offer alternatives to increasing the resolution of the generated images.</p>

<h2 id="upscaling">Upscaling</h2>

<p>The first approach uses image upscaling to increase the resolution of an image. Traditional upscaling methods, such as interpolation, don’t increase the inherent resolution of the image. The upscaler used here actually fills in missing details to increase resolution (NOTE: the upscaler itself is based on stable diffusion architecture). The architecture for the approach is outlined below:</p>

<p><img src="/assets/images/generative_figure2.png" alt="upscaling" width="400" /></p>

<p>Figure adapted from https://huggingface.co/blog/stable_diffusion</p>

<p>The benefit of this approach is that it uses the same DDPM from step 1 (which produces images of 64x64) and then the upscaler increases the resolution to 256x256.</p>

<p>The disadvantage of this approach is that the upscaler is not tuned specifically for your data (although it could be with additional training). It also makes a slow process (sampling the DDPM) even slower because you are performing two indepdenent steps (sampling then upscaling).</p>

<h2 id="latent-model">Latent model</h2>

<p>The second approach to increasing resolution was introduced in <a href="https://arxiv.org/abs/2112.10752">“High-Resolution Image Synthesis with Latent Diffusion Models”</a>. The idea behind this approach is to surround the DDPM with a pretrained variational autoencoder<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>. The DDPM then learns to denoise the latent space (which also happens to be 64x64) instead of the image space. To create a new sample:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. generate random noise in the shape of the latent space
2. use the DDPM to denoise the input
3. use the decoder to transform the latent space back into image space (512x512)
</code></pre></div></div>

<p><img src="/assets/images/generative_figure3.png" alt="latent" width="400" /></p>

<p>Figure adapted from https://huggingface.co/blog/stable_diffusion</p>

<p>Unfortunately I did not have enough Colab credits to fully train this variant<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup>. Although the model outputs images that are 512x512, I admit that they don’t look very bird-like. Here is a single full image created after 50 epochs of training:</p>

<p><img src="/assets/images/latent_bird.png" alt="latent image" /></p>

<h1 id="conditional-image-generation-stable-diffusion">Conditional Image Generation (Stable Diffusion)</h1>

<p>Up to this point we have not had any control over what kind of bird gets synthesized. The final step is to condition the DDPM on another input (usually text, but it could also be another image). NOTE: In order to train such a model, the training data would require both text and captions. The CUB-2011 dataset does not provide captions and I also discovered that significantly more compute is needed to train the latent models so I will use a pretrained Stable Diffusion model.</p>

<p><img src="/assets/images/generative_figure4.png" alt="stable diffusion" width="600" /></p>

<p>Figure adapted from https://huggingface.co/blog/stable_diffusion</p>

<p>Here is an example output:</p>

<p><img src="/assets/images/eastern_bluebird_stable.png" alt="stable diffusion output" /></p>

<p>I generated the image above with the implementation provided by Lyumin Zhang called <a href="https://github.com/lllyasviel/Fooocus">Fooocus</a>. It is a pre-tuned version of <a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0">StabilityAI’s Stable Diffusion XL model</a>. You can generate your own images using the provided Colab notebook -&gt; 
<a target="_blank" href="https://colab.research.google.com/github/https://colab.research.google.com/github/lllyasviel/Fooocus/blob/main/fooocus_colab.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" />
</a></p>

<h1 id="conclusion">Conclusion</h1>

<p>Generative AI is currently experiencing a boom, with new research and products coming out every day. The code for this experiment can be found at my <a href="https://github.com/dlfelps/ml_portfolio">ML portfolio website</a>. I would like to leave you with a final conversation from Microsoft’s <a href="https://copilot.microsoft.com/">Copilot</a>:</p>

<blockquote>
  <p style="text-align: right;">Me:</p>
  <p style="text-align: right;">Can you write a poem about generative ai?</p>

  <p>Copilot:</p>

  <p>Sure, I’d love to! Here’s a poem about generative AI:</p>

  <p>In circuits deep, where data flows, A spark ignites, a thought that grows. From silicon dreams, a mind takes flight, Crafting worlds in the dead of night.</p>

  <p>With algorithms as its guiding star, It reaches realms both near and far. From pixels bright to words that sing, Generative AI creates everything.</p>

  <p>It learns from patterns, vast and wide, In every byte, where secrets hide. A painter’s brush, a poet’s pen, It brings to life what once was then.</p>

  <p>Yet in its core, a humble start, A tool to aid the human heart. For in each line and crafted scene, It mirrors dreams, both bold and serene.</p>

  <p>So here’s to code that dreams and dares, To generative AI, with whom we share, A future bright, where minds entwine, In harmony, both yours and mine.</p>
</blockquote>

<p>END OF CONVERSATION</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>This particular autoencoder preserves spatial information by compressing a 512x512x3 image into a latent space of 64x64x4. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>As a comparison, in <a href="https://arxiv.org/abs/2112.10752">“High-Resolution Image Synthesis with Latent Diffusion Models”</a>, they trained a latent model on FFHQ for 283 hours on an A100. This would cost an equivalent of $370 in Colab compute units so you will have to forgive me for stopping early! <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/computer-vision" class="page__taxonomy-item p-category" rel="tag">computer-vision</a><span class="sep">, </span>
    
      <a href="/tags/generative" class="page__taxonomy-item p-category" rel="tag">generative</a><span class="sep">, </span>
    
      <a href="/tags/ml-portfolio" class="page__taxonomy-item p-category" rel="tag">ml-portfolio</a><span class="sep">, </span>
    
      <a href="/tags/stable-diffusion" class="page__taxonomy-item p-category" rel="tag">stable-diffusion</a>
    
    </span>
  </p>




        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-08-01T00:00:00+00:00">August 1, 2024</time></p>

      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Experiment+19%20https%3A%2F%2Fdlfelps.github.io%2F2024%2F08%2F01%2Fgenerative.html" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fdlfelps.github.io%2F2024%2F08%2F01%2Fgenerative.html" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://dlfelps.github.io/2024/08/01/generative.html" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/2024/07/01/adversarial.html" class="pagination--pager" title="Experiment 18
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

      
    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 <a href="https://dlfelps.github.io">.NET Experiments</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>









  </body>
</html>
