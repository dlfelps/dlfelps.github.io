<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://dlfelps.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://dlfelps.github.io/" rel="alternate" type="text/html" /><updated>2022-07-03T13:23:28+00:00</updated><id>https://dlfelps.github.io/feed.xml</id><title type="html">.NET Experiments</title><subtitle>Bill Nye meets Bill Gates ;)</subtitle><entry><title type="html">Experiment 03</title><link href="https://dlfelps.github.io/2022/06/25/Reproducible-Foundations.html" rel="alternate" type="text/html" title="Experiment 03" /><published>2022-06-25T00:00:00+00:00</published><updated>2022-06-25T00:00:00+00:00</updated><id>https://dlfelps.github.io/2022/06/25/Reproducible-Foundations</id><content type="html" xml:base="https://dlfelps.github.io/2022/06/25/Reproducible-Foundations.html"><![CDATA[<p>This post introduces the tools that I use to make my code reproducible. NOTE: I have only tested this on <em>smallish</em> projects and there certainly are other ways to create reproducible software.</p>

<h2 id="introduction">Introduction</h2>

<p>T</p>
<ul>
  <li>code hosting</li>
  <li>container technology</li>
  <li>continuous integration / continuous delivery</li>
  <li>non-technical considerations (licensing)</li>
</ul>

<!--

1. Intro
  - need for reproducibility
  - in science
  - in software
  - in machine learning

2. Basic tools
  - Docker (links to learning resources)
  - Gitlab/Github 
  - CI/CD
  - permissive licensing

3. Producing reporducible builds
  - choice of baseline (LTS)
  - provide multiple options (multiple-platforms)
    - local install w/ ci/cd
    - docker-compose local (build)
  - push build complexity to lowest level

4. CI/CD
  - Gitlab runner w/ docker
  - (optional) docker registry

5. Publishing
  - code should be publish to allow someone (most likely yourself) to reproduce it
  - but it shouldnt be required; also provide standalone executables

-->]]></content><author><name></name></author><category term="reproducible" /><category term="net" /><category term="docker" /><summary type="html"><![CDATA[This post introduces the tools that I use to make my code reproducible. NOTE: I have only tested this on smallish projects and there certainly are other ways to create reproducible software.]]></summary></entry><entry><title type="html">Experiment 02</title><link href="https://dlfelps.github.io/2022/06/20/Reproducible-Dotnet-Series.html" rel="alternate" type="text/html" title="Experiment 02" /><published>2022-06-20T00:00:00+00:00</published><updated>2022-06-20T00:00:00+00:00</updated><id>https://dlfelps.github.io/2022/06/20/Reproducible-Dotnet-Series</id><content type="html" xml:base="https://dlfelps.github.io/2022/06/20/Reproducible-Dotnet-Series.html"><![CDATA[<p>The next few posts take step back to examine the benefits of creating reproducible software. We will explore:</p>
<ul>
  <li>the continuosly reproducible mindset (this post)</li>
  <li>foundational tools for reproducibility (Exp 03)</li>
  <li>creating a continuously reproducible .NET project (Exp 04)</li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>Scientific experiments must be repeatable and reproducable to be considered scientific. Reproducability in software is optional - software that works but is not reproducible is still successful software. I hope to convince you that the overhead required to create reproducible software is low compared to the benefits that it provides future developers, even if the only future developer is you.</p>

<h2 id="defining-reproducible-software">Defining reproducible software</h2>

<p>It is useful to clarify our definition of reproducibility within the context of software development. Let P<sub>0</sub> represent a stable, compiling build of a codebase that results in a <em>correct</em> program. The reproducibility test for P<sub>0</sub> is as follows:</p>

<blockquote>
  <p>Does the code/documentation for P<sub>0</sub> contain sufficient information to reproduce the <em>correct</em> program from a clean environment? (Yes/No)</p>
</blockquote>

<p>Next, let P<sub>1</sub> represent the code (in the new environment) that has undergone a substantial change that <em>modified the build environment.</em> We can reapply the reproducibilty test to P<sub>1</sub>. The number of times that code passes the reproducibility test can be defined as its reproducibility level [0..N].</p>

<p>It may be useful to name a few of these levels.</p>

<ul>
  <li><em>Irreproducible</em> - Reproducibility level 0; P<sub>0</sub> failed the reproducibility test.</li>
  <li><em>One-time reproducible</em> - Reproducibility level 1; P<sub>0</sub> passed the reproducibility test, but P<sub>1</sub> failed.</li>
  <li><em>Continuously reproducible</em> - Reproducibility level 2+; If P<sub>0</sub> and P<sub>1</sub> pass the reproducibility test then it is indicitave that the code is written in a way that supports reproducibility for future generations of the code.</li>
</ul>

<h2 id="the-continuously-reproducible-mindset">The continuously reproducible mindset</h2>

<p>How many times have you pulled a project from Github only to have it fail to compile?</p>

<blockquote>
  <p>It works on my machine ¯\_(ツ)_/¯</p>
</blockquote>

<p>We can reduce this problem by expanding our mindset to strive for <strong>continuously reproducible</strong> code. The key to creating continuously reproducible code is create a simple workflow that rebuilds the project from a clean environment (preferably Windows, Linux, and OSX). This allows you to isolate undocumented side-effects that can occur in your local development environment (e.g. relying on a tool available locally that is not installed during the build process).</p>

<p>Continuosly reproducible code balances the need to solve the current problem with the need to redeploy the codebase to new systems. If this doesn’t seem worthwhile, then it might be helpful to imagine that your code (P<sub>0</sub>) will be extended by a different developer in a substantial way (P<sub>1</sub>) before it is returned to you for another round of development (P<sub>2</sub>). The time spent during the initial phase of development to create a build process that is easy to replicate across platforms (and modify as needed) will payoff in the long run.</p>

<p>But what if you are the only developer that will ever use this code? I have  found the continuosly reproducible mindset to be helpful in my personal projects for tracking down build-related problems and ensuring robust code that works on multiple platforms (I develop locally on Windows but sometimes require a linux binary).</p>

<h2 id="measuring-the-longevity-of-a-build">Measuring the longevity of a build</h2>

<p>If a specific build passes the reproducibility test then its longevity can be measured. Longevity is a measure of the period of time between the first time the build passes the reproducibility test and the last time it passes. All builds eventually fail because some dependency of the build process will fail (including the language itself - .NET Framework 3.5 was released in November  2007 but it is no longer available from Microsoft).</p>

<p align="center">
  <img width="600" height="400" src="/assets/images/fight_club.jpg" />
</p>

<p>Longevity is measured for a single build configuration. Namely, P<sub>0</sub> will have a certain longevity, but P<sub>1</sub>’s longevity may be shorter or longer depending on the changes made to its build configuration. Although true longevity can only be calculated after the build fails, developers can make conscious decisions to maximize the expected longevity of their code:</p>
<ul>
  <li>prefer dependencies that offer long term support (e.g. choose .NET 6 LTS even after .NET 7 is released) <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></li>
  <li>prefer dependencies that minimize the number of <a href="https://fsprojects.github.io/Paket/faq.html#What-does-transitive-dependencies-mean">transitive dependencies</a></li>
  <li>specify dependencies using <a href="https://fsprojects.github.io/Paket/nuget-dependencies.html#Pinned-version-constraint">pinned version constraints</a> <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></li>
  <li>if using Docker, build from standard base images <sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup></li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Reproducibility is relatively easy with modern software development tools. The crux of the problem is giving future developers the ability to:</p>
<ol>
  <li>easily recreate the initial development environment across multiple platforms/architectures</li>
  <li>continue to make changes to the code that does not break this process</li>
</ol>

<p>In the next few posts I will describe the current (circa 2022) best practices for reproducibility and demonstrate how to apply them to an existing code base.</p>

<h4 id="footnotes">Footnotes</h4>

<!--

1. Intro
  - need for reproducibility
  - in science
  - in software
  - in machine learning

2. Basic tools
  - Docker (links to learning resources)
  - Gitlab/Github 
  - CI/CD
  - permissive licensing

3. Producing reporducible builds
  - choice of baseline (LTS)
  - provide multiple options (multiple-platforms)
    - local install w/ ci/cd
    - docker-compose local (build)
  - push build complexity to lowest level

4. CI/CD
  - Gitlab runner w/ docker
  - (optional) docker registry

5. Publishing
  - code should be publish to allow someone (most likely yourself) to reproduce it
  - but it shouldnt be required; also provide standalone executables

-->

<!--
https://www.nature.com/articles/s41562-016-0021


The problem
A hallmark of scientific creativity is the ability to see novel and unexpected patterns in data. John Snow's identification of links between cholera and water supply17, Paul Broca's work on language lateralization18 and Jocelyn Bell Burnell's discovery of pulsars19 are examples of breakthroughs achieved by interpreting observations in a new way. However, a major challenge for scientists is to be open to new and important insights while simultaneously avoiding being misled by our tendency to see structure in randomness. The combination of apophenia (the tendency to see patterns in random data), confirmation bias (the tendency to focus on evidence that is in line with our expectations or favoured explanation) and hindsight bias (the tendency to see an event as having been predictable only after it has occurred) can easily lead us to false conclusions20. Thomas Levenson documents the example of astronomers who became convinced they had seen the fictitious planet Vulcan because their contemporary theories predicted its existence21. Experimenter effects are an example of this kind of bias22.

Over-interpretation of noise is facilitated by the extent to which data analysis is rapid, flexible and automated23. In a high-dimensional dataset, there may be hundreds or thousands of reasonable alternative approaches to analysing the same data24,25. For example, in a systematic review of functional magnetic resonance imaging (fMRI) studies, Carp showed that there were almost as many unique analytical pipelines as there were studies26. If several thousand potential analytical pipelines can be applied to high-dimensional data, the generation of false-positive findings is highly likely. For example, applying almost 7,000 analytical pipelines to a single fMRI dataset resulted in over 90% of brain voxels showing significant activation in at least one analysis27.

During data analysis it can be difficult for researchers to recognize P-hacking28 or data dredging because confirmation and hindsight biases can encourage the acceptance of outcomes that fit expectations or desires as appropriate, and the rejection of outcomes that do not as the result of suboptimal designs or analyses. Hypotheses may emerge that fit the data and are then reported without indication or recognition of their post hoc origin7. This, unfortunately, is not scientific discovery, but self-deception29. Uncontrolled, it can dramatically increase the false discovery rate. We need measures to counter the natural tendency of enthusiastic scientists who are motivated by discovery to see patterns in noise.


-->
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Microsoft patches .NET LTS releases for 3 years while current releases are only patched for 18 months. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>While it may seem counterintuitive to limit the available versions of your dependencies, it improves control over the automatic dependency resolver. This is in line with the continuously reproducible mindset and future developers are always free to update the version if they encounter a conflict. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Docker terms of service include a 6 month image retention limit on inactive images for free accounts <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="reproducible" /><category term="net" /><summary type="html"><![CDATA[The next few posts take step back to examine the benefits of creating reproducible software. We will explore: the continuosly reproducible mindset (this post) foundational tools for reproducibility (Exp 03) creating a continuously reproducible .NET project (Exp 04)]]></summary></entry><entry><title type="html">Experiment 01</title><link href="https://dlfelps.github.io/2022/06/06/DOTNET-Publishing-Options.html" rel="alternate" type="text/html" title="Experiment 01" /><published>2022-06-06T00:00:00+00:00</published><updated>2022-06-06T00:00:00+00:00</updated><id>https://dlfelps.github.io/2022/06/06/DOTNET-Publishing-Options</id><content type="html" xml:base="https://dlfelps.github.io/2022/06/06/DOTNET-Publishing-Options.html"><![CDATA[<p>This experiment explores various publishing options associated with .NET, including:</p>
<ul>
  <li>framework-dependent vs self-contained</li>
  <li>Windows vs Linux vs OSX</li>
  <li>and more…</li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>The traditional way to distribute a .NET application is by compiling code (e.g. C#) into bytecode known as <a href="https://en.wikipedia.org/wiki/Common_Intermediate_Language">CIL</a>. This bytecode can then be run by anyone who has installed the .NET runtime environment (also known as <a href="https://docs.microsoft.com/en-us/dotnet/standard/clr">CLR</a>). The process is illustrated below:</p>

<p align="center">
  <img width="416" height="480" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Overview_of_the_Common_Language_Infrastructure_2015.svg/416px-Overview_of_the_Common_Language_Infrastructure_2015.svg.png" />
</p>

<p>This compilation strategy is known as <a href="https://en.wikipedia.org/wiki/Dynamic_compilation">dynamic compilation</a> and was popularized by the Java Virtual Machine. Some languages like C++ use static compilers that produce native code for a specific platform directly. This code cannot be shared across platforms, but users also do not need to install a runtime environment.</p>

<p>Although the .NET runtime is simple to install, some users may still prefer a “standalone” executable that does not require this extra step. Since .NET 3.0 developers have been able to publish their code as “self-contained” - which means that it includes the runtime environment along with their compiled bytecode. The only real downside is that it creates executables that are larger than they would be otherwise.</p>

<p>This study explores the effect of publishing code as “self-contained” across various platforms and the extent to which the size can be reduced through advanced publishing options.</p>

<h2 id="setup">Setup</h2>

<p>I strive to make all of my experiments reproducible. Please follow the installation instructions below to configure your system to run the experiment.</p>

<ol>
  <li>Install <a href="https://dotnet.microsoft.com/en-us/download">.NET 6.0 SDK</a> (not the Runtime option)</li>
  <li>Obtain the <a href="https://github.com/dlfelps/WaveFunctionCollapse">WaveFunctionCollapse</a> repo; you can either:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/dlfelps/WaveFunctionCollapse.git
</code></pre></div>    </div>
    <p>or <a href="https://github.com/dlfelps/WaveFunctionCollapse/archive/refs/heads/master.zip">download</a> and unzip</p>
  </li>
  <li>Run the provided commands for each experiment (see below)</li>
</ol>

<h2 id="experiment">Experiment</h2>

<h3 id="framework-dependent-vs-self-contained">Framework-dependent vs self-contained</h3>

<p>The first part of the experiment compares two deployment modes. In the framework-dependent distribution mode only the application and third-party assemblies are included; it is assumed that users will have the .NET runtime installed on their system. In the self-contained distribution mode the .NET runtime and runtime libraries included as well.</p>

<p>Another difference between the two modes is that the framework-dependent mode produces a cross-platform binary, which means it can run on any platform. The self-contained option must be created for a specific platform (in this case we use win-x64 but any valid runtime in the <a href="https://docs.microsoft.com/en-us/dotnet/core/rid-catalog">RID Catalog</a> may be chosen).</p>

<p>To run this portion of the experiment execute the following commands within your WaveFunctionCollapse folder (I am using Powershell for Windows):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dotnet publish -c "exp_1a_framework-dependent"
dotnet publish -c "exp_1a_self-contained" -r win-x64 --self-contained true
</code></pre></div></div>
<p>The published folders can be found at</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>..\WaveFunctionCollapse\bin\exp_1a_framework-dependent\net6.0\publish\
..\WaveFunctionCollapse\bin\exp_1a_self-contained\net6.0\win-x64\publish
</code></pre></div></div>
<p>Execution of the created application is different in each case. From the framework-dependent publish folder the entrypoint is the cross-platform binary using the dotnet command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dotnet WaveFunctionCollapse.dll
</code></pre></div></div>
<p>From the self-contained publish folder the entrypoint is simply the platform-specific executable (Windows here):</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./WaveFunctionCollapse.exe
</code></pre></div></div>
<p>We measure the size of the corresponding publish folders to compare the final size of the distributable application in each case.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th style="text-align: center">size (MB)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>framework-dependent (cross-platform)</td>
      <td style="text-align: center">1.53</td>
    </tr>
    <tr>
      <td>self-contained (win-x64 only)</td>
      <td style="text-align: center">68.7</td>
    </tr>
  </tbody>
</table>

<p>The difference does appear to be approximately the size of a binary installation of .NET 6.0 (for Windows is 68.1 MB). But 68 MB barely registers on a 500 GB hard drive. My bigger concern is that self-contained distributions limit the systems that can use it since they are platform specific. In the next experiment we look at platforms besides Windows. <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></p>

<h3 id="varying-the-platform-of-self-contained-releases">Varying the platform of self-contained releases</h3>

<p>In this part of the experiment we determine the extent to which the target platform changes the size of the publish folder. To run this portion of the experiment execute the following commands within your WaveFunctionCollapse folder:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dotnet publish -c "exp_1b_linux"  -r linux-x64 --self-contained true
dotnet publish -c "exp_1b_osx_x64"  -r osx-x64 --self-contained true
dotnet publish -c "exp_1b_osx12_arm"  -r osx.12-arm64 --self-contained true
</code></pre></div></div>
<p>I measured the size of the corresponding publish folders and also included the results from the self-contained win-x64 from the previous section.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th style="text-align: center">size (MB)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>win-x64</td>
      <td style="text-align: center">68.7</td>
    </tr>
    <tr>
      <td>linux-x64</td>
      <td style="text-align: center">68.5</td>
    </tr>
    <tr>
      <td>osx-x64</td>
      <td style="text-align: center">68.5</td>
    </tr>
    <tr>
      <td>osx12-arm</td>
      <td style="text-align: center">75.0</td>
    </tr>
  </tbody>
</table>

<p>There is no significant difference between the sizes of these various platforms. They are all approximately the size of the original application code plus the size of the binary installation of .NET 6.0 for the corresponding platform.</p>

<h3 id="trimming">Trimming</h3>

<p>To finish out this experiment I wanted to explore one of the advanced publishing options that dotnet provides - trimming. When you enable trimming the compiler tries to reduce deployment size by including only the minimum  subset of the framework assemblies that are needed to run the application. The unused parts of the framework are trimmed from the packaged application. But there is a risk that the compiler miscalculates which parts are necessary during build time causing a failure at run time.</p>

<p>To run this portion of the experiment execute the following commands within your WaveFunctionCollapse folder:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dotnet publish -c "exp_1c_windows"  -r win-x64 --self-contained true -p:PublishTrimmed=true
dotnet publish -c "exp_1c_linux"  -r linux-x64 --self-contained true -p:PublishTrimmed=true
dotnet publish -c "exp_1c_osx_x64"  -r osx-x64 --self-contained true -p:PublishTrimmed=true
dotnet publish -c "exp_1c_osx12_arm"  -r osx.12-arm64 --self-contained true -p:PublishTrimmed=true
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th> </th>
      <th style="text-align: center">original size (MB)</th>
      <th style="text-align: center">reduced size (MB)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>win-x64</td>
      <td style="text-align: center">68.7</td>
      <td style="text-align: center">22.1</td>
    </tr>
    <tr>
      <td>linux-x64</td>
      <td style="text-align: center">68.5</td>
      <td style="text-align: center">23.8</td>
    </tr>
    <tr>
      <td>osx-x64</td>
      <td style="text-align: center">68.5</td>
      <td style="text-align: center">22.7</td>
    </tr>
    <tr>
      <td>osx12-arm</td>
      <td style="text-align: center">75.0</td>
      <td style="text-align: center">21.9</td>
    </tr>
  </tbody>
</table>

<p>The results show that the reduced size is about one third of the original size. But the risk that the application <em>may</em> fail at runtime does not seem worth the memory savings for most applications. However in this case I was able to verify that the Windows and Linux distributions worked correctly (OSX was not tested).</p>

<h2 id="limitations-of-study">Limitations of study</h2>

<p>The results shown above represent an experiment for a single code base. You may get different results for your own code (especially when trimming). If you do repeat this study on a different code base I would appreciate it if you would share the results for comparison!</p>

<h2 id="conclusion">Conclusion</h2>

<p>.NET makes it amazingly simple to publish code that works on almost any device. In order to share your application with the widest audience I recommend publishing both the framework-dependent and (untrimmed) self-contained versions for all major platforms. I do not generally recommend trimming unless you are able to thoroughly test the created executables.</p>

<h3 id="references">References</h3>

<ol>
  <li><a href="https://docs.microsoft.com/en-us/dotnet/core/deploying/">.NET application publishing overview</a></li>
  <li><a href="https://github.com/mxgmn/WaveFunctionCollapse">WaveFunctionCollapse</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Common_Language_Infrastructure">CLI</a></li>
</ol>

<h3 id="footnotes">Footnotes</h3>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>By default the framework-dependent mode creates both a cross-platform binary and a platform-specific executable that targets the current platform. In my case the publish folder included a platform-specific file called WaveFunctionCollapse.exe (since I use Windows). This unnecessary  file was removed before the folder size was measured. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><category term="net" /><summary type="html"><![CDATA[This experiment explores various publishing options associated with .NET, including: framework-dependent vs self-contained Windows vs Linux vs OSX and more…]]></summary></entry><entry><title type="html">Welcome to my blog!</title><link href="https://dlfelps.github.io/2022/06/04/My-First-Post.html" rel="alternate" type="text/html" title="Welcome to my blog!" /><published>2022-06-04T00:00:00+00:00</published><updated>2022-06-04T00:00:00+00:00</updated><id>https://dlfelps.github.io/2022/06/04/My-First-Post</id><content type="html" xml:base="https://dlfelps.github.io/2022/06/04/My-First-Post.html"><![CDATA[<p>My goal for this site is to document the “experiments” that I perform while exploring various computer science topics. I hope to include future posts on the following topics:</p>

<ul>
  <li>.NET</li>
  <li>domain driven design</li>
  <li>software architecture</li>
</ul>

<p>If you have any suggestions or comments please email me at <a href="mailto:dlfelps@gmail.com">dlfelps@gmail.com</a>.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[My goal for this site is to document the “experiments” that I perform while exploring various computer science topics. I hope to include future posts on the following topics:]]></summary></entry></feed>